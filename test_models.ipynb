{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneInteractionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, num_layers, num_features=24, dropout=0.1):\n",
    "        super(GeneInteractionModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=128, kernel_size=(2, 3), stride=1, padding=(0, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=108, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(108),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=108, out_channels=108, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(108),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=108, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.r = nn.GRU(128, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.s = nn.Linear(2 * hidden_size, 12, bias=False)\n",
    "\n",
    "        self.d = nn.Sequential(\n",
    "            nn.Linear(num_features, 96, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(96, 64, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 128, bias=False)\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(140),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(140, 1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g = torch.squeeze(self.c1(g), 2)\n",
    "        g = self.c2(g)\n",
    "        g, _ = self.r(torch.transpose(g, 1, 2))\n",
    "        g = self.s(g[:, -1, :])\n",
    "\n",
    "        x = self.d(x)\n",
    "\n",
    "        out = self.head(torch.cat((g, x), dim=1))\n",
    "\n",
    "        return F.softplus(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepCas9Model(nn.Module):\n",
    "    def __init__(self, filter_size, filter_num, node_1=80, node_2=60):\n",
    "        super(DeepCas9Model, self).__init__()\n",
    "        length = 30\n",
    "\n",
    "        # Define layers using torch.nn\n",
    "        self.conv1 = nn.Conv2d(4, filter_num[0], kernel_size=(1, filter_size[0]))\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.conv2 = nn.Conv2d(filter_num[0], filter_num[1], kernel_size=(1, filter_size[1]))\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.conv3 = nn.Conv2d(filter_num[1], filter_num[2], kernel_size=(1, filter_size[2]))\n",
    "        self.pool3 = nn.AvgPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(filter_num[0] * ((length - filter_size[0]) // 2 + 1), node_1)\n",
    "        self.dense2 = nn.Linear(filter_num[1] * ((length - filter_size[1]) // 2 + 1), node_2)\n",
    "        self.output_layer = nn.Linear(filter_num[2] * ((length - filter_size[2]) // 2 + 1), 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.conv1(inputs))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = F.relu(self.dense2(x))\n",
    "        outputs = self.output_layer(x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def preprocess_seq(data, seq_length):\n",
    "\n",
    "    seq_onehot = np.zeros((len(data), 1, seq_length, 4), dtype=float)\n",
    "\n",
    "    for l in range(len(data)):\n",
    "        for i in range(seq_length):\n",
    "            try:\n",
    "                data[l][i]\n",
    "            except Exception:\n",
    "                print(data[l], i, seq_length, len(data))\n",
    "\n",
    "            if   data[l][i] in \"Aa\":  seq_onehot[l, 0, i, 0] = 1\n",
    "            elif data[l][i] in \"Cc\":  seq_onehot[l, 0, i, 1] = 1\n",
    "            elif data[l][i] in \"Gg\":  seq_onehot[l, 0, i, 2] = 1\n",
    "            elif data[l][i] in \"Tt\":  seq_onehot[l, 0, i, 3] = 1\n",
    "            elif data[l][i] in \"Xx\":  pass\n",
    "            elif data[l][i] in \"Nn.\": pass\n",
    "            else:\n",
    "                print(\"[Input Error] Non-ATGC character \" + data[l])\n",
    "                sys.exit()\n",
    "\n",
    "    return seq_onehot\n",
    "\n",
    "\n",
    "# Create an instance of the custom model\n",
    "filter_size = [3, 5, 7]\n",
    "filter_num  = [100, 70, 40]\n",
    "node_1 = 80\n",
    "node_2 = 60\n",
    "\n",
    "custom_model = DeepCas9Model(filter_size=filter_size, filter_num=filter_num, node_1=node_1, node_2=node_2)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=0.005)\n",
    "loss_object = nn.MSELoss()\n",
    "\n",
    "# Function for training the model\n",
    "def train_step(inputs, targets):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = custom_model(inputs)\n",
    "    loss = loss_object(predictions, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Function for predicting using the model\n",
    "def predict(inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = custom_model(inputs)\n",
    "    return outputs.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_context</th>\n",
       "      <th>indel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTCTGCCTTGTTTCTTTCCTCTCTGGGTCG</td>\n",
       "      <td>24.287805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACGACCTTCAGCTCAGTGACAGTGAGGACA</td>\n",
       "      <td>69.500438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGGACGACGACTACAATAAGCCTCTGGATC</td>\n",
       "      <td>25.994760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCAGCAAACTGACGGAGAACCTTGTGGCCC</td>\n",
       "      <td>57.964590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCGGCAGATATCCGTGAAGGCTCTAGGTAC</td>\n",
       "      <td>39.355020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>GGGAATACGACGACCAGAGAGCGCTGGAGA</td>\n",
       "      <td>40.853256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>TCATGGATTTCCTGGCTCGGGGACTGGTCT</td>\n",
       "      <td>11.480880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>GCCTTGTTTCTTTCCTCTCTGGGTCGGATT</td>\n",
       "      <td>63.861469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>TCGCACCTGATAGAGCATGTGACAAGGAGA</td>\n",
       "      <td>51.650932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>CCCTCTGCGCATGGTCTTCCGGGGTGGCTC</td>\n",
       "      <td>40.019124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12832 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Target_context      indel\n",
       "0      TTCTGCCTTGTTTCTTTCCTCTCTGGGTCG  24.287805\n",
       "1      ACGACCTTCAGCTCAGTGACAGTGAGGACA  69.500438\n",
       "2      AGGACGACGACTACAATAAGCCTCTGGATC  25.994760\n",
       "3      GCAGCAAACTGACGGAGAACCTTGTGGCCC  57.964590\n",
       "4      CCGGCAGATATCCGTGAAGGCTCTAGGTAC  39.355020\n",
       "...                               ...        ...\n",
       "12827  GGGAATACGACGACCAGAGAGCGCTGGAGA  40.853256\n",
       "12828  TCATGGATTTCCTGGCTCGGGGACTGGTCT  11.480880\n",
       "12829  GCCTTGTTTCTTTCCTCTCTGGGTCGGATT  63.861469\n",
       "12830  TCGCACCTGATAGAGCATGTGACAAGGAGA  51.650932\n",
       "12831  CCCTCTGCGCATGGTCTTCCGGGGTGGCTC  40.019124\n",
       "\n",
       "[12832 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('docs/dataset/DeepSpCas9_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train dataset\n",
    "\n",
    "random_seed = 0\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "x_train = preprocess_seq(df['Target_context'], 30)\n",
    "y_train = df['indel']\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12832, 1, 30, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12832, 1, 30, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = preprocess_seq(df['Target_context'], 30)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24.2878, 69.5004, 25.9948,  ..., 63.8615, 51.6509, 40.0191])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def input_generator(TEST_X):\n",
    "    test_batch = 500\n",
    "    TEST_Z = np.zeros((TEST_X.shape[0], 1), dtype=float)\n",
    "\n",
    "    for i in range(int(np.ceil(float(TEST_X.shape[0]) / float(test_batch)))):\n",
    "        TEST_X[i * test_batch:(i + 1) * test_batch]\n",
    "\n",
    "    list_score = sum(TEST_Z.tolist(), [])\n",
    "\n",
    "    return list_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (30 x 1). Kernel size: (1 x 5). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 25\u001b[0m train_ \u001b[39m=\u001b[39m train_step(x_train, y_train)\n",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(inputs, targets)\u001b[0m\n\u001b[0;32m     17\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m predictions \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     20\u001b[0m loss \u001b[39m=\u001b[39m loss_object(predictions, targets)\n\u001b[0;32m     21\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mDeepCas9Model.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     27\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(inputs))\n\u001b[0;32m     28\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(x)\n\u001b[1;32m---> 29\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x))\n\u001b[0;32m     30\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(x)\n\u001b[0;32m     31\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x))\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\torch2\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (30 x 1). Kernel size: (1 x 5). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "\n",
    "# Create an instance of the custom model\n",
    "filter_size = [3, 5, 7]\n",
    "filter_num  = [100, 70, 40]\n",
    "node_1 = 80\n",
    "node_2 = 60\n",
    "\n",
    "model = DeepCas9Model(filter_size=filter_size, filter_num=filter_num, node_1=node_1, node_2=node_2).to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "loss_object = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Function for training the model\n",
    "def train_step(inputs, targets):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(inputs)\n",
    "    loss = loss_object(predictions, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "train_ = train_step(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
