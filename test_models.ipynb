{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(4064, 2, 74, 4)\n"
     ]
    }
   ],
   "source": [
    "# An file for on-target DeepPE (pre-)training.\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def preprocess_seq(data, seq_length):\n",
    "\n",
    "    seq_onehot = np.zeros((len(data), 1, seq_length, 4), dtype=float)\n",
    "\n",
    "    for l in range(len(data)):\n",
    "        for i in range(seq_length):\n",
    "            try:\n",
    "                data[l][i]\n",
    "            except Exception:\n",
    "                print(data[l], i, seq_length, len(data))\n",
    "\n",
    "            if   data[l][i] in \"Aa\":  seq_onehot[l, 0, i, 0] = 1\n",
    "            elif data[l][i] in \"Cc\":  seq_onehot[l, 0, i, 1] = 1\n",
    "            elif data[l][i] in \"Gg\":  seq_onehot[l, 0, i, 2] = 1\n",
    "            elif data[l][i] in \"Tt\":  seq_onehot[l, 0, i, 3] = 1\n",
    "            elif data[l][i] in \"Xx\":  pass\n",
    "            elif data[l][i] in \"Nn.\": pass\n",
    "            else:\n",
    "                print(\"[Input Error] Non-ATGC character \" + data[l])\n",
    "                sys.exit()\n",
    "\n",
    "    return seq_onehot\n",
    "def seq_concat(data, col1='WT74_On', col2='Edited74_On', seq_length=74):\n",
    "    wt = preprocess_seq(data[col1], seq_length)\n",
    "    ed = preprocess_seq(data[col2], seq_length)\n",
    "    g = np.concatenate((wt, ed), axis=1)\n",
    "    g = 2 * g - 1\n",
    "\n",
    "    return g\n",
    "\n",
    "# LOAD & PREPROCESS GENES\n",
    "\n",
    "data_id = 'DP_variant_293T_PE2_Conv_220428'\n",
    "train_file = pd.read_csv('docs/dataset/%s.csv' % data_id)\n",
    "\n",
    "gene_path = 'docs/dataset/genes/%s.npy' % data_id\n",
    "if not os.path.isfile(gene_path):\n",
    "    g_train = seq_concat(train_file)\n",
    "    np.save(gene_path, g_train)\n",
    "else:\n",
    "    g_train = np.load(gene_path)\n",
    "\n",
    "print(type(g_train))\n",
    "print(g_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([4064, 2, 74, 4])\n"
     ]
    }
   ],
   "source": [
    "g_train = torch.tensor(g_train, dtype=torch.float32, device=device)\n",
    "print(type(g_train))\n",
    "print(g_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([4064, 4, 2, 74])\n"
     ]
    }
   ],
   "source": [
    "g = g_train.permute((0, 3, 1, 2))\n",
    "print(type(g))\n",
    "print(g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepCas9Model(nn.Module):\n",
    "    def __init__(self, filter_size, filter_num, node_1=80, node_2=60):\n",
    "        super(DeepCas9Model, self).__init__()\n",
    "        length = 30\n",
    "\n",
    "        # Define layers using torch.nn\n",
    "        self.conv1 = nn.Conv2d(4, filter_num[0], kernel_size=(1, filter_size[0]))\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(filter_num[0], filter_num[1], kernel_size=(1, filter_size[1]))\n",
    "        self.norm2 = nn.BatchNorm2d(filter_num[1])\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(1, 2), stride=(1, 2))\n",
    "\n",
    "        # 원래 DeepSpCas9은 sequential하게 가는 것이 아니긴 한데... 어차피 이미 달라진 모델이니..\n",
    "        # 위에 2d CNN을 2번 거치고, 이후에는 1d CNN\n",
    "\n",
    "        self.conv3 = nn.Conv1d(filter_num[1], filter_num[2], kernel_size=filter_size[2])\n",
    "        self.pool3 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense1 = nn.Linear(filter_num[0] * ((length - filter_size[0]) // 2 + 1), node_1)\n",
    "        self.dense2 = nn.Linear(filter_num[1] * ((length - filter_size[1]) // 2 + 1), node_2)\n",
    "        self.output_layer = nn.Linear(filter_num[2] * ((length - filter_size[2]) // 2 + 1), 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.conv1(inputs))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.norm2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.squeeze(x, 2) # dimmension 축소\n",
    "        print('step marker')\n",
    "        x = F.relu(self.conv3(x)) # Error\n",
    "        print('step marker')\n",
    "        x = self.pool3(x)\n",
    "        print('step marker')\n",
    "        x = self.flatten(x)\n",
    "        print('step marker')\n",
    "        x = F.relu(self.dense1(x))\n",
    "        print('step marker')\n",
    "        x = F.relu(self.dense2(x))\n",
    "        print('step marker')\n",
    "        outputs = self.output_layer(x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def preprocess_seq(data, seq_length):\n",
    "\n",
    "    seq_onehot = np.zeros((len(data), 1, seq_length, 4), dtype=float)\n",
    "\n",
    "    for l in range(len(data)):\n",
    "        for i in range(seq_length):\n",
    "            try:\n",
    "                data[l][i]\n",
    "            except Exception:\n",
    "                print(data[l], i, seq_length, len(data))\n",
    "\n",
    "            if   data[l][i] in \"Aa\":  seq_onehot[l, 0, i, 0] = 1\n",
    "            elif data[l][i] in \"Cc\":  seq_onehot[l, 0, i, 1] = 1\n",
    "            elif data[l][i] in \"Gg\":  seq_onehot[l, 0, i, 2] = 1\n",
    "            elif data[l][i] in \"Tt\":  seq_onehot[l, 0, i, 3] = 1\n",
    "            elif data[l][i] in \"Xx\":  pass\n",
    "            elif data[l][i] in \"Nn.\": pass\n",
    "            else:\n",
    "                print(\"[Input Error] Non-ATGC character \" + data[l])\n",
    "                sys.exit()\n",
    "\n",
    "    return seq_onehot\n",
    "\n",
    "\n",
    "# Create an instance of the custom model\n",
    "filter_size = [3, 5, 7]\n",
    "filter_num  = [100, 70, 40]\n",
    "node_1 = 80\n",
    "node_2 = 60\n",
    "\n",
    "custom_model = DeepCas9Model(filter_size=filter_size, filter_num=filter_num, node_1=node_1, node_2=node_2)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=0.005)\n",
    "loss_object = nn.MSELoss()\n",
    "\n",
    "# Function for training the model\n",
    "def train_step(inputs, targets):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = custom_model(inputs)\n",
    "    loss = loss_object(predictions, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Function for predicting using the model\n",
    "def predict(inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = custom_model(inputs)\n",
    "    return outputs.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class GeneInteractionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size=128, num_layers=1, num_features=24, dropout=0.1):\n",
    "        super(GeneInteractionModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=128, kernel_size=(1, 3), stride=1, padding=(0, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=108, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(108),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=108, out_channels=108, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(108),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv1d(in_channels=108, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.r = nn.GRU(128, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.s = nn.Linear(2 * hidden_size, 12, bias=False)\n",
    "\n",
    "        self.d = nn.Sequential(\n",
    "            nn.Linear(num_features, 96, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(96, 64, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 128, bias=False)\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(140),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(140, 1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, g):\n",
    "        g = torch.squeeze(self.c1(g), 2)\n",
    "        g = self.c2(g)\n",
    "        g, _ = self.r(torch.transpose(g, 1, 2))\n",
    "        g = self.s(g[:, -1, :])\n",
    "        \n",
    "        out = self.head(torch.cat((g), dim=1))\n",
    "\n",
    "        return F.softplus(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_context</th>\n",
       "      <th>indel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTCTGCCTTGTTTCTTTCCTCTCTGGGTCG</td>\n",
       "      <td>24.287805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACGACCTTCAGCTCAGTGACAGTGAGGACA</td>\n",
       "      <td>69.500438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGGACGACGACTACAATAAGCCTCTGGATC</td>\n",
       "      <td>25.994760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCAGCAAACTGACGGAGAACCTTGTGGCCC</td>\n",
       "      <td>57.964590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCGGCAGATATCCGTGAAGGCTCTAGGTAC</td>\n",
       "      <td>39.355020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>GGGAATACGACGACCAGAGAGCGCTGGAGA</td>\n",
       "      <td>40.853256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>TCATGGATTTCCTGGCTCGGGGACTGGTCT</td>\n",
       "      <td>11.480880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>GCCTTGTTTCTTTCCTCTCTGGGTCGGATT</td>\n",
       "      <td>63.861469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>TCGCACCTGATAGAGCATGTGACAAGGAGA</td>\n",
       "      <td>51.650932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>CCCTCTGCGCATGGTCTTCCGGGGTGGCTC</td>\n",
       "      <td>40.019124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12832 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Target_context      indel\n",
       "0      TTCTGCCTTGTTTCTTTCCTCTCTGGGTCG  24.287805\n",
       "1      ACGACCTTCAGCTCAGTGACAGTGAGGACA  69.500438\n",
       "2      AGGACGACGACTACAATAAGCCTCTGGATC  25.994760\n",
       "3      GCAGCAAACTGACGGAGAACCTTGTGGCCC  57.964590\n",
       "4      CCGGCAGATATCCGTGAAGGCTCTAGGTAC  39.355020\n",
       "...                               ...        ...\n",
       "12827  GGGAATACGACGACCAGAGAGCGCTGGAGA  40.853256\n",
       "12828  TCATGGATTTCCTGGCTCGGGGACTGGTCT  11.480880\n",
       "12829  GCCTTGTTTCTTTCCTCTCTGGGTCGGATT  63.861469\n",
       "12830  TCGCACCTGATAGAGCATGTGACAAGGAGA  51.650932\n",
       "12831  CCCTCTGCGCATGGTCTTCCGGGGTGGCTC  40.019124\n",
       "\n",
       "[12832 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('docs/dataset/DeepSpCas9_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train dataset\n",
    "\n",
    "random_seed = 0\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "x_train = preprocess_seq(df['Target_context'], 30)\n",
    "y_train = df['indel']\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32, device=device)\n",
    "x_train = x_train.permute((0, 3, 1, 2))\n",
    "y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12832, 4, 1, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step marker\n",
      "step marker\n",
      "step marker\n",
      "step marker\n",
      "step marker\n",
      "step marker\n",
      "step marker\n",
      "step marker\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (40x1x1). Calculated output size: (40x1x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\github_project\\genet\\test_models.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m train_ \u001b[39m=\u001b[39m train_step(x_train, y_train)\n",
      "\u001b[1;32me:\\github_project\\genet\\test_models.ipynb Cell 8\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(inputs, targets)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(inputs, targets):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     predictions \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_object(predictions, targets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\gsyu\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32me:\\github_project\\genet\\test_models.ipynb Cell 8\u001b[0m in \u001b[0;36mDeepCas9Model.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)) \u001b[39m# Error\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstep marker\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool3(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstep marker\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/github_project/genet/test_models.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n",
      "File \u001b[1;32mc:\\Users\\gsyu\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gsyu\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:547\u001b[0m, in \u001b[0;36mAvgPool1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 547\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mavg_pool1d(\n\u001b[0;32m    548\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[0;32m    549\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcount_include_pad)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (40x1x1). Calculated output size: (40x1x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "\n",
    "# Create an instance of the custom model\n",
    "filter_size = [3, 5, 5]\n",
    "filter_num  = [100, 70, 40]\n",
    "node_1 = 80\n",
    "node_2 = 60\n",
    "\n",
    "model = DeepCas9Model(filter_size=filter_size, filter_num=filter_num, node_1=node_1, node_2=node_2).to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "loss_object = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Function for training the model\n",
    "def train_step(inputs, targets):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(inputs)\n",
    "    loss = loss_object(predictions, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "train_ = train_step(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 226.00 MiB (GPU 0; 8.00 GiB total capacity; 7.21 GiB already allocated; 0 bytes free; 7.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\github_project\\genet\\test_models.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m train_loss \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m train_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m pred \u001b[39m=\u001b[39m model(x_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(pred\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, y_train)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\github_project\\genet\\test_models.ipynb Cell 11\u001b[0m in \u001b[0;36mGeneInteractionModel.forward\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m g \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc1(g), \u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc2(g)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m g, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr(torch\u001b[39m.\u001b[39;49mtranspose(g, \u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms(g[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/github_project/genet/test_models.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead(torch\u001b[39m.\u001b[39mcat((g), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:942\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    941\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    943\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    944\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    945\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    946\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 226.00 MiB (GPU 0; 8.00 GiB total capacity; 7.21 GiB already allocated; 0 bytes free; 7.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "\n",
    "# Create an instance of the custom model\n",
    "filter_size = [3, 5, 5]\n",
    "filter_num  = [100, 70, 40]\n",
    "node_1 = 80\n",
    "node_2 = 60\n",
    "\n",
    "model = DeepCas9Model(filter_size=filter_size, filter_num=filter_num, node_1=node_1, node_2=node_2).to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "loss_object = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# PARAMS\n",
    "\n",
    "batch_size = 2048\n",
    "learning_rate = 5e-3\n",
    "weight_decay = 5e-2\n",
    "T_0 = 10\n",
    "T_mult = 1\n",
    "hidden_size = 128\n",
    "n_layers = 1\n",
    "n_epochs = 10\n",
    "n_models = 5\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "\n",
    "for m in range(n_models):\n",
    "\n",
    "    random_seed = m\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    model = GeneInteractionModel(hidden_size=hidden_size, num_layers=n_layers).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    for epoch in pbar:\n",
    "        train_loss = []\n",
    "        train_count = 0\n",
    "\n",
    "        pred = model(x_train)\n",
    "        print(pred.shape)\n",
    "        loss = criterion(pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(x.size(0) * loss.detach().cpu().numpy())\n",
    "        train_count += x.size(0)\n",
    "\n",
    "        train_loss = sum(train_loss) / train_count\n",
    "        pbar.set_description('M {:02} | {:.4}'.format(m, train_loss))\n",
    "\n",
    "    torch.save(model.state_dict(),'docs/models/test_model_{}.pt'.format(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
